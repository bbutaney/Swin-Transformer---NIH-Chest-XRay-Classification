{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following cells were run in Google Colab to train a Swin Transformer for image classification on the NIH dataset of ~100k chest x-rays.\n",
        "\n",
        "This is a multiclass, multilabel problem, with images being classified as showing one or more of 15 diseases.\n",
        "\n",
        "The files used in this notebook can be downloaded here: https://www.kaggle.com/datasets/nih-chest-xrays/data. A description of the data can be\n",
        "found here: https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HdHB1DFEa5w"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Classify image files from \"images\" folder in GDrive as test, train, or validation\n",
        "\n",
        "path = '/content/drive/MyDrive/cxr_indiv/images'\n",
        "\n",
        "# put train and test files from txt file to dict\n",
        "loc_dict = {} # call loc_dict[filename] to see if an image is train, validation, or test\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/cxr_indiv/train_val_list.txt\", \"r\") as a_file:\n",
        "  for line in a_file:\n",
        "    # IF IN THE CURRENT IMAGE FOLDER, THEN\n",
        "    stripped_line = line.strip()\n",
        "    if os.path.exists(path + '/' + stripped_line):\n",
        "      loc_dict[stripped_line] = a_file.name.replace(\"/content/drive/MyDrive/cxr_indiv/\", \"\").replace(\"_val_list.txt\", \"\").strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPA1kNZXEnXV"
      },
      "outputs": [],
      "source": [
        "# split training data for validation\n",
        "train_length = 0\n",
        "for i in loc_dict:\n",
        "  if loc_dict[i] == 'train':\n",
        "    train_length += 1\n",
        "\n",
        "validation_percent = 0.1\n",
        "\n",
        "desired_length = (1.0 - validation_percent) * train_length\n",
        "for i in loc_dict:\n",
        "  if loc_dict[i] == 'train':\n",
        "    loc_dict[i] = 'valid'\n",
        "    train_length -=1\n",
        "  if train_length <= desired_length:\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G7izzR6Enbb",
        "outputId": "d6c54e2d-3fea-4389-c4bf-d8aeddbffa21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n"
          ]
        }
      ],
      "source": [
        "# split csv into train and test\n",
        "# loop through csv file\n",
        "# with conditional to separate train and test images\n",
        "\n",
        "import pandas as pd\n",
        "full_csv = pd.read_csv(\"/content/drive/MyDrive/cxr_indiv/Data_Entry_2017_v2020.csv\")\n",
        "\n",
        "train_df = pd.DataFrame({})\n",
        "valid_df = pd.DataFrame({})\n",
        "test_df = pd.DataFrame({})\n",
        "for i in range(len(full_csv['Image Index'])):\n",
        "  try:\n",
        "    loc_dict[full_csv['Image Index'][i]] == 'train'\n",
        "\n",
        "    if loc_dict[full_csv['Image Index'][i]] == 'train':\n",
        "      train_df = train_df.append(full_csv.iloc[i])\n",
        "    elif loc_dict[full_csv['Image Index'][i]] == 'valid':\n",
        "      valid_df = valid_df.append(full_csv.iloc[i])\n",
        "    # elif loc_dict[full_csv['Image Index'][i]] == 'test':\n",
        "    #   test_df = test_df.append(full_csv.iloc[i])\n",
        "    else:\n",
        "      print(\"error\")\n",
        "  except KeyError:\n",
        "    continue\n",
        "\n",
        "# create sets of labels and remove no finding\n",
        "count = 0\n",
        "for i in range(len(train_df['Finding Labels'])):\n",
        "  if type(train_df['Finding Labels'].iloc[i]) != set:\n",
        "    temp = train_df['Finding Labels'].iloc[i].split('|')\n",
        "    train_df['Finding Labels'].iloc[i] = set(temp)\n",
        "\n",
        "for i in range(len(valid_df['Finding Labels'])):\n",
        "  if type(valid_df['Finding Labels'].iloc[i]) != set:\n",
        "    temp = valid_df['Finding Labels'].iloc[i].split('|')\n",
        "    valid_df['Finding Labels'].iloc[i] = set(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7fVsr9rEne6",
        "outputId": "76661b2b-2777-47ca-d05e-7ad5168f72ba"
      },
      "outputs": [],
      "source": [
        "# install the necessary dependencies:\n",
        "# !pip install torch\n",
        "# !pip install torchvision\n",
        "# !pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFh_OWIcEniJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "import torch\n",
        "import io\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "import torchvision\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        temp = annotations_file['Finding Labels']\n",
        "        mlb = sklearn.preprocessing.MultiLabelBinarizer()\n",
        "        self.img_labels = pd.DataFrame(mlb.fit_transform(temp),columns=mlb.classes_)\n",
        "        print(mlb.classes_)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.annot = annotations_file\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.annot['Image Index'].iloc[idx])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        image.resize_(3, 224, 224)\n",
        "        return image, label.to_numpy() # torch tensor, numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ3CNJCVEnlZ",
        "outputId": "4091905c-370c-4445-89f2-c8acc2c15959"
      },
      "outputs": [],
      "source": [
        "# create the dataset\n",
        "import torchvision\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((224, 224))])\n",
        "train_dataset = CustomImageDataset(train_df, path)\n",
        "valid_dataset = CustomImageDataset(valid_df, path) # validation data still held in train folder\n",
        "\n",
        "# create a data loader for train, valid, and test sets\n",
        "batches = 32\n",
        "\n",
        "train_dl = DataLoader(train_dataset, batch_size=batches, shuffle=True)\n",
        "# train_features, train_labels = next(iter(train_dl))\n",
        "\n",
        "valid_dl = DataLoader(valid_dataset, batch_size=batches, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K72Kt_BVEnoo",
        "outputId": "76b47f0a-6a98-4928-b0f8-212267ba8b4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxl5llFBGjsd",
        "outputId": "37604151-d9c1-43ff-f5ef-4fe3bb5d1c47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22kto1k.pth\" to /root/.cache/torch/hub/checkpoints/swin_base_patch4_window7_224_22kto1k.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvWiy6LnEnx-"
      },
      "outputs": [],
      "source": [
        "# Using BCELoss and sigmoid separately\n",
        "criterion = torch.nn.BCELoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.05)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmvm31phGjj9"
      },
      "outputs": [],
      "source": [
        "def optimizer_to(optim, device):\n",
        "    for param in optim.state.values():\n",
        "        # Not sure there are any global tensors in the state dict\n",
        "        if isinstance(param, torch.Tensor):\n",
        "            param.data = param.data.to(device)\n",
        "            if param._grad is not None:\n",
        "                param._grad.data = param._grad.data.to(device)\n",
        "        elif isinstance(param, dict):\n",
        "            for subparam in param.values():\n",
        "                if isinstance(subparam, torch.Tensor):\n",
        "                    subparam.data = subparam.data.to(device)\n",
        "                    if subparam._grad is not None:\n",
        "                        subparam._grad.data = subparam._grad.data.to(device)\n",
        "\n",
        "prevpath = 'state_1.pth'\n",
        "prevpath = '/content/drive/MyDrive/tesim/'+ prevpath\n",
        "state = torch.load(prevpath)\n",
        "model.load_state_dict(state['state_dict'])\n",
        "optimizer.load_state_dict(state['optimizer'])\n",
        "optimizer_to(optimizer, device)\n",
        "criterion.load_state_dict(state['criterion'])\n",
        "optimizer.param_groups[0]['lr'] = 0.00001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mR9StSkEnr2"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgfGrI97En04",
        "outputId": "fbc808ae-188f-474d-e1c3-6c8a58f7a986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.75\n"
          ]
        }
      ],
      "source": [
        "from torch.autograd.grad_mode import F\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pred = torch.Tensor([[0,1, 1, 0], [1,1,1,1]])\n",
        "truth = torch.Tensor([[1, 1, 0, 0], [1,1,1,1]])\n",
        "\n",
        "def find_single_accuracy(pred, truth):\n",
        "  length = 0\n",
        "  true_neg_and_pos = 0\n",
        "\n",
        "  # get tensor size\n",
        "  for i in pred:\n",
        "    length+=1\n",
        "\n",
        "  # count true positives and negatives\n",
        "  for i in range(length):\n",
        "    if pred[i].item() == truth[i].item():\n",
        "      true_neg_and_pos+=1\n",
        "\n",
        "  return true_neg_and_pos / length\n",
        "\n",
        "\n",
        "\n",
        "def find_accuracy(pred: torch.Tensor, truth: torch.Tensor):\n",
        "  \"\"\" returns accuracy given a k-D prediction (one hot encoded) and the target for those k samples\n",
        "  \"\"\"\n",
        "  accuracies = []\n",
        "  length = 0\n",
        "  for i in pred:\n",
        "    length+=1\n",
        "\n",
        "  for i in range(length):\n",
        "    accuracies.append(find_single_accuracy(pred[i], truth[i]))\n",
        "\n",
        "  return sum(accuracies) / len(accuracies)\n",
        "\n",
        "print(find_accuracy(pred, truth))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfccKhb9XiNa"
      },
      "outputs": [],
      "source": [
        "optimizer.param_groups[0]['capturable'] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksy0nfdyE6O9"
      },
      "outputs": [],
      "source": [
        "from numpy import vstack\n",
        "from numpy import argmax\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from torch.nn import Linear\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Softmax\n",
        "from torch.nn import Module\n",
        "import copy\n",
        "\n",
        "savepath = 'state_1.pth' # for updating model state dict during validation\n",
        "optimizer.param_groups[0]['lr'] = 0.001\n",
        "\n",
        "# train model\n",
        "from tqdm import tqdm\n",
        "# enumerate epochs\n",
        "running_loss = 0\n",
        "current_batch_accs = []\n",
        "epoch_accs = []\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in range(3):\n",
        "    # enumerate mini batches\n",
        "    for (inputs, targets) in tqdm(train_dl):\n",
        "      model.train()\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      # clear the gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # compute the model output and establish layers\n",
        "      lin = nn.Linear(1000, 15)\n",
        "      lin = lin.to(device)\n",
        "      sig = nn.Sigmoid()\n",
        "      yhat = model(inputs.cuda().float())\n",
        "      # linear layer\n",
        "      yhat = lin(yhat)\n",
        "      yhat = yhat.to(device)\n",
        "      # sigmoid layer\n",
        "      yhat = sig(yhat)\n",
        "\n",
        "      # set loss\n",
        "      try:\n",
        "        loss = criterion(yhat, targets.float())\n",
        "      except:\n",
        "        remaining_images = len(train_dataset) % batches\n",
        "        loss = criterion(yhat, targets.float())\n",
        "\n",
        "      yhat = yhat.detach()\n",
        "\n",
        "      print(loss.item())\n",
        "      # credit assignment\n",
        "      loss.backward()\n",
        "      running_loss += loss.item()\n",
        "      print(running_loss)\n",
        "\n",
        "      # update model weights\n",
        "      optimizer.step()\n",
        "      optimizer.param_groups[0]['lr'] /= 10\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    predictions, actuals = list(), list()\n",
        "    torch.cuda.empty_cache()\n",
        "    min_valid_loss = float('inf')\n",
        "    valid_loss = 0\n",
        "    for (inputs, targets) in valid_dl:\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      yhat = model(inputs.float())\n",
        "      yhat = lin(yhat)\n",
        "      yhat = sig(yhat)\n",
        "      yhat = torch.round(yhat, decimals=0)\n",
        "      yhat = yhat.detach()\n",
        "\n",
        "      actual = targets.cpu().float().numpy()\n",
        "\n",
        "      predictions.append(yhat)\n",
        "      actuals.append(actual)\n",
        "      yhat = yhat.detach()\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      # calculate batch accuracy\n",
        "      print('batch accuracy:', str(find_accuracy(yhat, actual)))\n",
        "      current_batch_accs.append(find_accuracy(yhat, actual))\n",
        "      valid_loss = loss.item() * inputs.size(0)\n",
        "\n",
        "    if min_valid_loss > valid_loss:\n",
        "        min_valid_loss = valid_loss\n",
        "        \n",
        "        # Saving State Dict\n",
        "        state = {\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'criterion': criterion.state_dict()\n",
        "        }\n",
        "        torch.save(state, '/content/drive/MyDrive/tesim/'+ savepath)\n",
        "\n",
        "    # calculate epoch accuracy\n",
        "    predictions, actuals = vstack([i.cpu() for i in predictions]), vstack(actuals)\n",
        "    acc = (actuals, predictions)\n",
        "    print(' for epoch', (epoch+1))\n",
        "    print('epoch accuracy: ' + str(sum(current_batch_accs) / len(current_batch_accs)))\n",
        "    print('epoch loss: ' + str(running_loss / train_dataset.__len__()))\n",
        "    running_loss = 0\n",
        "    epoch_accs.append(sum(current_batch_accs) / len(current_batch_accs))\n",
        "    current_batch_accs = []\n",
        "\n",
        "print('====================================')\n",
        "print('all epoch accuracies:', str(epoch_accs))\n",
        "print('avg epoch acc:', str(sum(epoch_accs) / len(epoch_accs)))\n",
        "print('highest epoch acc was epoch', str(epoch_accs.index(max(epoch_accs)) + 1), 'with', str(max(epoch_accs)))\n",
        "print('lowest epoch acc was epoch', str(epoch_accs.index(min(epoch_accs)) + 1), 'with', str(min(epoch_accs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtV-7-jWE6Ub"
      },
      "outputs": [],
      "source": [
        "# save state dict\n",
        "state = {\n",
        "    'state_dict': model.state_dict(),\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "    'criterion': criterion.state_dict()\n",
        "}\n",
        "torch.save(state, '/content/drive/MyDrive/tesim/'+ savepath)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Jul12_images_2_8.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
